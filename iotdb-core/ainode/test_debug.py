#!/usr/bin/env python3
# test_timesfm_debug.py

import os
import sys
import inspect
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# æ¨¡æ‹Ÿç¯å¢ƒ
class MockLogger:
    def __init__(self, name=None): self.name = name
    def debug(self, msg, *args, **kwargs): print(f"DEBUG: {msg}")
    def info(self, msg, *args, **kwargs): print(f"INFO: {msg}")
    def warning(self, msg, *args, **kwargs): print(f"WARNING: {msg}")
    def error(self, msg, *args, **kwargs): print(f"ERROR: {msg}")

class MockAINodeConfig:
    def get_ain_models_dir(self): return "data/ainode/models"
    def get_ain_builtin_models_dir(self): return "data/ainode/models/weights"

class MockAINodeDescriptor:
    def get_config(self): return MockAINodeConfig()

os.environ['AINODE_TEST'] = 'true'
sys.modules['ainode.core.log'] = type('MockLogModule', (), {'Logger': MockLogger})()
sys.modules['ainode.core.config'] = type('MockConfigModule', (), {'AINodeDescriptor': MockAINodeDescriptor})()

# å¯¼å…¥æ¨¡å—
try:
    from ainode.core.model.timesfm.configuration_timesfm import TimesFmConfig
    from ainode.core.model.timesfm.modeling_timesfm import TimesFmForPrediction
    print("âœ“ Successfully imported TimesFM modules")
except ImportError as e:
    print(f"âœ— Import error: {e}")
    sys.exit(1)

def debug_model_interface():
    """è°ƒè¯•æ¨¡å‹æ¥å£"""
    print("ğŸ” Debugging TimesFM Model Interface")
    print("=" * 50)
    
    # åˆ›å»ºé…ç½®å’Œæ¨¡å‹
    config = TimesFmConfig(
        patch_length=16,
        context_length=128,
        horizon_length=32,
        hidden_size=64,
        num_hidden_layers=1,
        num_attention_heads=2,
        head_dim=32,
        freq_size=3
    )
    
    model = TimesFmForPrediction(config)
    
    # æ£€æŸ¥æ¨¡å‹ç±»å±‚æ¬¡ç»“æ„
    print(f"ğŸ“‹ Model Class Hierarchy:")
    mro = TimesFmForPrediction.__mro__
    for i, cls in enumerate(mro):
        print(f"  {i}: {cls.__name__} ({cls.__module__})")
    
    # æ£€æŸ¥forwardæ–¹æ³•
    print(f"\nğŸ” Forward Method Analysis:")
    if hasattr(model, 'forward'):
        forward_method = getattr(model, 'forward')
        print(f"  - Has forward method: âœ“")
        print(f"  - Forward method type: {type(forward_method)}")
        print(f"  - Forward method: {forward_method}")
        
        # è·å–æ–¹æ³•ç­¾å
        try:
            sig = inspect.signature(forward_method)
            print(f"  - Method signature: {sig}")
            print(f"  - Parameters:")
            for name, param in sig.parameters.items():
                print(f"    - {name}: {param}")
        except Exception as e:
            print(f"  - Could not get signature: {e}")
    else:
        print(f"  - Has forward method: âœ—")
    
    # æ£€æŸ¥æ‰€æœ‰å¯ç”¨æ–¹æ³•
    print(f"\nğŸ“ Available Methods:")
    methods = [method for method in dir(model) if callable(getattr(model, method)) and not method.startswith('_')]
    for method in sorted(methods):
        print(f"  - {method}")
    
    # æ£€æŸ¥ç‰¹æ®Šæ–¹æ³•
    print(f"\nğŸ”§ Special Methods:")
    special_methods = [method for method in dir(model) if method.startswith('_') and callable(getattr(model, method))]
    important_methods = ['__call__', '_forward_unimplemented', 'forward']
    for method in important_methods:
        if method in special_methods:
            try:
                method_obj = getattr(model, method)
                sig = inspect.signature(method_obj)
                print(f"  - {method}: {sig}")
            except:
                print(f"  - {method}: present but can't get signature")
        else:
            print(f"  - {method}: not found")
    
    # å°è¯•ä¸åŒçš„è°ƒç”¨æ–¹å¼
    print(f"\nğŸ§ª Testing Different Call Methods:")
    import torch
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    test_data = [torch.randn(128) for _ in range(2)]
    
    # æµ‹è¯•1: ç›´æ¥è°ƒç”¨æ¨¡å‹ (ä½¿ç”¨__call__)
    try:
        print("  1. Testing model() call...")
        with torch.no_grad():
            output = model(test_data)
        print(f"     âœ“ model() works, output type: {type(output)}")
    except Exception as e:
        print(f"     âœ— model() failed: {e}")
    
    # æµ‹è¯•2: ä½¿ç”¨past_valueså‚æ•°
    try:
        print("  2. Testing model(past_values=...)...")
        with torch.no_grad():
            output = model(past_values=test_data)
        print(f"     âœ“ model(past_values=...) works, output type: {type(output)}")
    except Exception as e:
        print(f"     âœ— model(past_values=...) failed: {e}")
    
    # æµ‹è¯•3: æ£€æŸ¥æ˜¯å¦æœ‰predictæ–¹æ³•
    if hasattr(model, 'predict'):
        try:
            print("  3. Testing model.predict()...")
            with torch.no_grad():
                output = model.predict(test_data)
            print(f"     âœ“ model.predict() works, output type: {type(output)}")
        except Exception as e:
            print(f"     âœ— model.predict() failed: {e}")
    else:
        print("  3. model.predict() not available")
    
    # æµ‹è¯•4: æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–é¢„æµ‹æ–¹æ³•
    prediction_methods = ['predict_step', 'generate', 'forecast']
    for method_name in prediction_methods:
        if hasattr(model, method_name):
            try:
                print(f"  4. Testing model.{method_name}()...")
                method = getattr(model, method_name)
                with torch.no_grad():
                    output = method(test_data)
                print(f"     âœ“ model.{method_name}() works, output type: {type(output)}")
            except Exception as e:
                print(f"     âœ— model.{method_name}() failed: {e}")
    
    print(f"\nâœ… Debug analysis complete!")

if __name__ == "__main__":
    debug_model_interface()