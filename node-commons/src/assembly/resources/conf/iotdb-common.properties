#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#

####################
### Thrift Configuration
####################

# Datatype: boolean
# rpc_thrift_compression_enable=false

# if true, a snappy based compression method will be called before sending data by the network
# Datatype: boolean
# this feature is under development, set this as false before it is done.
# rpc_advanced_compression_enable=false

# Datatype: int
# rpc_selector_thread_num=1

# Datatype: int
# rpc_min_concurrent_client_num=1

# Datatype: int
# rpc_max_concurrent_client_num=65535

# thrift max frame size, 512MB by default
# Datatype: int
# thrift_max_frame_size=536870912

# thrift init buffer size
# Datatype: int
# thrift_init_buffer_size=1024

# Thrift socket and connection timeout between raft nodes, in milliseconds.
# Datatype: int
# connection_timeout_ms=20000

# The maximum number of clients that can be idle for a node's InternalService.
# When the number of idle clients on a node exceeds this number, newly returned clients will be released
# Datatype: int
# core_connection_for_internal_service=100

# The maximum number of clients that can be applied for a node's InternalService
# Datatype: int
# max_connection_for_internal_service=100

# selector thread (TAsyncClientManager) nums for async thread in a clientManager
# Datatype: int
# selector_thread_nums_of_client_manager=1

####################
### Procedure Configuration
####################


# Default number of worker thread count
# Datatype: int
# procedure_core_worker_thread_size=4


# Default time interval of completed procedure cleaner work in, time unit is second
# Datatype: int
# procedure_completed_clean_interval=30


# Default ttl of completed procedure, time unit is second
# Datatype: int
# procedure_completed_evict_ttl=800

####################
### MPP Data Exchange Configuration
####################

# Datatype: int
# mpp_data_exchange_core_pool_size=10

# Datatype: int
# mpp_data_exchange_max_pool_size=10

# Datatype: int
# mpp_data_exchange_keep_alive_time_in_ms=1000

####################
### Continuous Query Configuration
####################

# How many thread will be set up to perform continuous queries. When <= 0, use max(1, CPU core number / 2).
# Datatype: int
# continuous_query_execution_thread=2

# Maximum number of continuous query tasks that can be pending for execution. When <= 0, the value is
# 64 by default.
# Datatype: int
# max_pending_continuous_query_tasks=64

# The size of log buffer for every CQ management operation plan. If the size of a CQ
# management operation plan is larger than this parameter, the CQ management operation plan
# will be rejected by CQManager.
# Datatype: int
# cqlog_buffer_size=1048576

# The number of threads in the scheduled thread pool that submit continuous query tasks periodically
# Datatype: int
# continuous_query_submit_thread=2

# The minimum value of the continuous query execution time interval
# Datatype: long(duration)
# continuous_query_min_every_interval_in_ms=1000


####################
### Mlog Buffer Configuration
####################

# Size of log buffer in each metadata operation plan(in byte).
# If the size of a metadata operation plan is larger than this parameter, then it will be rejected by SchemaRegion
# If it sets a value smaller than 0, use the default value 1024*1024
# Datatype: int
# mlog_buffer_size=1048576

# The cycle when metadata log is periodically forced to be written to disk(in milliseconds)
# If sync_mlog_period_in_ms = 0 it means force metadata log to be written to disk after each refreshment
# Set this parameter to 0 may slow down the operation on slow disk.
# sync_mlog_period_in_ms=100

####################
### Storage Engine Configuration
####################

# What will the system do when unrecoverable error occurs.
# Datatype: String
# Optional strategies are as follows:
# 1. CHANGE_TO_READ_ONLY: set system status to read-only and the system only accepts query operations.
# 2. SHUTDOWN: the system will be shutdown.
# handle_system_error=CHANGE_TO_READ_ONLY

# When a memTable's size (in byte) exceeds this, the memtable is flushed to disk. The default threshold is 1 GB.
# Datatype: long
# memtable_size_threshold=1073741824

# Whether to timed flush sequence tsfiles' memtables.
# Datatype: boolean
# enable_timed_flush_seq_memtable=false

# If a memTable's created time is older than current time minus this, the memtable will be flushed to disk.
# Only check sequence tsfiles' memtables.
# The default flush interval is 60 * 60 * 1000. (unit: ms)
# Datatype: long
# seq_memtable_flush_interval_in_ms=3600000

# The interval to check whether sequence memtables need flushing.
# The default flush check interval is 10 * 60 * 1000. (unit: ms)
# Datatype: long
# seq_memtable_flush_check_interval_in_ms=600000

# Whether to timed flush unsequence tsfiles' memtables.
# Datatype: boolean
# enable_timed_flush_unseq_memtable=true

# If a memTable's created time is older than current time minus this, the memtable will be flushed to disk.
# Only check unsequence tsfiles' memtables.
# The default flush interval is 60 * 60 * 1000. (unit: ms)
# Datatype: long
# unseq_memtable_flush_interval_in_ms=3600000

# The interval to check whether unsequence memtables need flushing.
# The default flush check interval is 10 * 60 * 1000. (unit: ms)
# Datatype: long
# unseq_memtable_flush_check_interval_in_ms=600000

# The sort algorithms used in the memtable's TVList
# TIM: default tim sort,
# QUICK: quick sort,
# BACKWARD: backward sort
# tvlist_sort_algorithm=TIM

# When the average point number of timeseries in memtable exceeds this, the memtable is flushed to disk. The default threshold is 100000.
# Datatype: int
# avg_series_point_number_threshold=100000

# How many threads can concurrently flush. When <= 0, use CPU core number.
# Datatype: int
# concurrent_flush_thread=0

# How many threads can concurrently execute query statement. When <= 0, use CPU core number.
# Datatype: int
# concurrent_query_thread=0

# How many threads can concurrently read data for raw data query. When <= 0, use CPU core number.
# Datatype: int
# concurrent_sub_rawQuery_thread=8

# Blocking queue size for read task in raw data query. Must >= 1.
# Datatype: int
# raw_query_blocking_queue_capacity=5

# whether take over the memory management by IoTDB rather than JVM when serializing memtable as bytes in memory
# (i.e., whether use ChunkBufferPool), value true, false
# Datatype: boolean
# chunk_buffer_pool_enable=false

# The amount of data iterate each time in server (the number of data strips, that is, the number of different timestamps.)
# Datatype: int
# batch_size=100000


# In one insert (one device, one timestamp, multiple measurements),
# if enable partial insert, one measurement failure will not impact other measurements
# Datatype: boolean
# enable_partial_insert=true

# the interval to log recover progress of each vsg when starting iotdb
# Datatype: int
# recovery_log_interval_in_ms=5000

# When the insert plan column count reaches the specified threshold, which means that the plan is relatively large. At this time, may be enabled multithreading.
# If the tablet is small, the time of each insertion is short.
# If we enable multithreading, we also need to consider the switching loss between threads,
# so we need to judge the size of the tablet.
# Datatype: int
# insert_multi_tablet_enable_multithreading_column_threshold=10

####################
### Upgrade Configurations
####################

# When there exists old version(0.9.x/v1) data, how many thread will be set up to perform upgrade tasks, 1 by default.
# Set to 1 when less than or equal to 0.
# Datatype: int
# upgrade_thread_num=1

####################
### Schema Engine Configuration
####################

# Choose the mode of schema engine. The value could be Memory,Schema_File and Rocksdb_based. If the provided value doesn't match any pre-defined value, Memory mode will be used as default.
# Datatype: string
# schema_engine_mode=Memory

# cache size for SchemaRegion.
# This cache is used to improve insert speed where all path check and TSDataType will be cached in SchemaRegion with corresponding Path.
# Datatype: int
# schema_region_device_node_cache_size=10000

# thread pool size for read operation in DataNode's coordinator.
# Datatype: int
# coordinator_read_executor_size=20

# thread pool size for write operation in DataNode's coordinator.
# Datatype: int
# coordinator_write_executor_size=50

# cache size for partition.
# This cache is used to improve partition fetch from config node.
# Datatype: int
# partition_cache_size=1000

# interval num for tag and attribute records when force flushing to disk
# When a certain amount of tag and attribute records is reached, they will be force flushed to disk
# It is possible to lose at most tag_attribute_flush_interval records
# tag_attribute_flush_interval=1000

####################
### Schema File Configuration
####################
# The minimum size (in bytes) allocated for a node in schema file
# A large number for this will make it faster while occupying more space, or otherwise
# The default 0 means if a flushed internal(entity) had less than 20 children, it will get a segment with the size calculated from total size of its children
# If no child, it would get a segment of 25 bytes, which is the size of segment header
# Datatype: short
# minimum_schema_file_segment_in_bytes=0

# The cache size for schema page in one schema file
# A bigger cache makes it faster but costs more space and more volatile when evicts item from cache
# Datatype: int
# page_cache_in_schema_file=1024

# The maximum number of log entries before the log is erased, impacting performance if too small
# Since pages in Schema File is set to 16KiB, the log can be restricted as 16Kib * schema_log_size, 256MB default
# Datatype: int
# schema_file_log_size=16384

####################
### Cache Configuration
####################

# whether to cache meta data(BloomFilter, ChunkMetadata and TimeSeriesMetadata) or not.
# Datatype: boolean
# meta_data_cache_enable=true

# Read memory Allocation Ratio: BloomFilterCache : ChunkCache : TimeSeriesMetadataCache : Coordinator : Operators : DataExchange : timeIndex in TsFileResourceList : others.
# The parameter form is a:b:c:d:e:f:g:h, where a, b, c, d, e, f, g and h are integers. for example: 1:1:1:1:1:1:1:1 , 1:100:200:50:200:200:200:50
# chunk_timeseriesmeta_free_memory_proportion=1:100:200:50:200:200:200:50

# Whether to enable LAST cache
# Datatype: boolean
# enable_last_cache=true


####################
### Memory Control Configuration
####################

# Whether to enable memory control
# Datatype: boolean
# enable_mem_control=true

# Memory Allocation Ratio: Write, Read, Schema, Consensus and Free Memory.
# The parameter form is a:b:c:d:e, where a, b, c, d and e are integers. for example: 1:1:1:1:1 , 6:2:1:1:1
# If you have high level of writing pressure and low level of reading pressure, please adjust it to for example 6:1:1:1:2
# write_read_schema_free_memory_proportion=3:3:1:1:2

# Schema Memory Allocation Ratio: SchemaRegion, SchemaCache, PartitionCache and LastCache.
# The parameter form is a:b:c:d, where a, b, c and d are integers. for example: 1:1:1:1 , 6:2:1:1
# In cluster mode, we recommend 5:3:1:1. In standalone mode, we recommend 8:1:0:1
# schema_memory_allocate_proportion=5:3:1:1

# Memory allocation ratio in StorageEngine: MemTable, Compaction
# The parameter form is a:b:c:d, where a, b, c and d are integers. for example: 8:2 , 7:3
# storage_engine_memory_proportion=8:2

# Max number of concurrent writing time partitions in one storage group
# This parameter is used to control total memTable number when memory control is disabled
# The max number of memTable is 4 * concurrent_writing_time_partition * storage group number
# Datatype: long
# concurrent_writing_time_partition=1

# primitive array size (length of each array) in array pool
# Datatype: int
# primitive_array_size=32

# size proportion for chunk metadata maintains in memory when writing tsfile
# Datatype: double
# chunk_metadata_size_proportion=0.1

# Ratio of write memory for invoking flush disk, 0.4 by default
# If you have extremely high write load (like batch=1000), it can be set lower than the default value like 0.2
# Datatype: double
# flush_proportion=0.4

# Ratio of write memory allocated for buffered arrays, 0.6 by default
# Datatype: double
# buffered_arrays_memory_proportion=0.6

# Ratio of write memory for rejecting insertion, 0.8 by default
# If you have extremely high write load (like batch=1000) and the physical memory size is large enough,
# it can be set higher than the default value like 0.9
# Datatype: double
# reject_proportion=0.8

# If memory cost of data region increased more than proportion of allocated memory for write, report to system. The default value is 0.001
# Datatype: double
# write_memory_variation_report_proportion=0.001

# When an inserting is rejected, waiting period (in ms) to check system again, 50 by default.
# If the insertion has been rejected and the read load is low, it can be set larger.
# Datatype: int
# check_period_when_insert_blocked=50

# size of ioTaskQueue. The default value is 10
# Datatype: int
# io_task_queue_size_for_flushing=10

# If true, we will estimate each query's possible memory footprint before executing it and deny it if its estimated memory exceeds current free memory
# Datatype: bool
# enable_query_memory_estimation=true


####################
### Select-Into Configuration
####################

# The maximum number of rows can be processed in insert-tablet-plan when executing select-into statements.
# When <= 0, use 10000.
# Datatype: int
# select_into_insert_tablet_plan_row_limit=10000

####################
### Compaction Configurations
####################
# sequence space compaction: only compact the sequence files
# Datatype: boolean
# enable_seq_space_compaction=true

# unsequence space compaction: only compact the unsequence files
# Datatype: boolean
# enable_unseq_space_compaction=true

# cross space compaction: compact the unsequence files into the overlapped sequence files
# Datatype: boolean
# enable_cross_space_compaction=true

# the selector of cross space compaction task
# Options: rewrite
# cross_selector=rewrite

# the compaction performer of cross space compaction task
# Options: read_point
# cross_performer=read_point

# the selector of inner sequence space compaction task
# Options: size_tiered
# inner_seq_selector=size_tiered

# the performer of inner sequence space compaction task
# Options: read_chunk
# inner_seq_performer=read_chunk

# the selector of inner unsequence space compaction task
# Options: size_tiered
# inner_unseq_selector=size_tiered

# the performer of inner unsequence space compaction task
# Options: read_point
# inner_unseq_performer=read_point

# The priority of compaction execution
# INNER_CROSS: prioritize inner space compaction, reduce the number of files first
# CROSS_INNER: prioritize cross space compaction, eliminate the unsequence files first
# BALANCE: alternate two compaction types
# compaction_priority=BALANCE

# The target tsfile size in compaction
# Datatype: long, Unit: byte
# target_compaction_file_size=1073741824

# The target chunk size in compaction and when memtable reaches this threshold, flush the memtable to disk.
# default is 1MB
# Datatype: long, Unit: byte
# target_chunk_size=1048576

# The target point nums in one chunk in compaction
# Datatype: long
# target_chunk_point_num=100000

# If the chunk size is lower than this threshold, it will be deserialize into points, default is 128 byte
# Datatype: long, Unit:byte
# chunk_size_lower_bound_in_compaction=128

# If the chunk size is lower than this threshold, it will be deserialize into points
# Datatype: long
# chunk_point_num_lower_bound_in_compaction=100

# The max file when selecting inner space compaction candidate files
# Datatype: int
# max_inner_compaction_candidate_file_num=30

# The max file when selecting cross space compaction candidate files
# At least one unseq file with it's overlapped seq files will be selected even exceeded this number
# Datatype: int
# max_cross_compaction_candidate_file_num=1000

# The max total size when selecting cross space compaction candidate files
# At least one unseq file with it's overlapped seq files will be selected even exceeded this number
# Datatype: long, Unit: byte
# max_cross_compaction_candidate_file_size=5368709120

# If one merge file selection runs for more than this time, it will be ended and its current
# selection will be used as final selection.
# When < 0, it means time is unbounded.
# Datatype: long, Unit: ms
# cross_compaction_file_selection_time_budget=30000

# How many threads will be set up to perform compaction, 10 by default.
# Set to 1 when less than or equal to 0.
# Datatype: int
# concurrent_compaction_thread=10

# The interval of compaction task schedule
# Datatype: long, Unit: ms
# compaction_schedule_interval_in_ms=60000

# The interval of compaction task submission
# Datatype: long, Unit: ms
# compaction_submission_interval_in_ms=60000

# The limit of write throughput merge can reach per second
# Datatype: int
# compaction_write_throughput_mb_per_sec=16

# The max executing time of query. unit: ms
# Datatype: int
# query_timeout_threshold=60000

# The maximum allowed concurrently executing queries
# Datatype: int
# max_allowed_concurrent_queries=1000

# The number of sub compaction threads to be set up to perform compaction.
# Currently only works for nonAligned data in cross space compaction and unseq inner space compaction.
# Set to 1 when less than or equal to 0.
# Datatype: int
# sub_compaction_thread_num=4


####################
### Write Ahead Log Configuration
####################

# Write mode of wal
# The details of these three modes are as follows:
# 1. DISABLE: the system will disable wal.
# 2. SYNC: the system will submit wal synchronously, write request will not return until its wal is fsynced to the disk successfully.
# 3. ASYNC: the system will submit wal asynchronously, write request will return immediately no matter its wal is fsynced to the disk successfully.
# The write performance order is DISABLE > ASYNC > SYNC, but only SYNC mode can ensure data durability.
# wal_mode=ASYNC

# Max number of wal nodes, each node corresponds to one wal directory
# The default value 0 means the number is determined by the system.
# Notice: this value affects write performance significantly.
# For non-SSD disks, values between one third and half of storage groups number are recommended.
# Datatype: int
# max_wal_nodes_num=0

# Duration a wal flush operation will wait before calling fsync
# A duration greater than 0 batches multiple wal fsync calls into one. This is useful when disks are slow or WAL write contention exists.
# Notice: this value affects write performance significantly, values in the range of 0ms-10ms are recommended.
# Datatype: long
# fsync_wal_delay_in_ms=3

# Buffer size of each wal node
# If it's a value smaller than 0, use the default value 16 * 1024 * 1024 bytes (16MB).
# Datatype: int
# wal_buffer_size_in_byte=16777216

# Blocking queue capacity of each wal buffer, restricts maximum number of WALEdits cached in the blocking queue.
# Datatype: int
# wal_buffer_queue_capacity=50

# Size threshold of each wal file
# When a wal file's size exceeds this, the wal file will be closed and a new wal file will be created.
# If it's a value smaller than 0, use the default value 10 * 1024 * 1024 (10MB).
# Datatype: long
# wal_file_size_threshold_in_byte=10485760

# Minimum ratio of effective information in wal files
# This value should be between 0.0 and 1.0
# If effective information ratio is below this value, MemTable snapshot or flush will be triggered.
# Increase this value when wal occupies too much disk space. But, if this parameter is too large, the write performance may decline.
# Datatype: double
# wal_min_effective_info_ratio=0.1

# MemTable size threshold for triggering MemTable snapshot in wal
# When a memTable's size (in byte) exceeds this, wal can flush this memtable to disk, otherwise wal will snapshot this memtable in wal.
# If it's a value smaller than 0, use the default value 8 * 1024 * 1024 bytes (8MB).
# Datatype: long
# wal_memtable_snapshot_threshold_in_byte=8388608

# MemTable's max snapshot number in wal
# If one memTable's snapshot number in wal exceeds this value, it will be flushed to disk.
# Datatype: int
# max_wal_memtable_snapshot_num=1

# The period when outdated wal files are periodically deleted
# If this value is too large, outdated wal files may not able to be deleted in time.
# If it's a value smaller than 0, use the default value 20 * 1000 ms (20 seconds).
# Datatype: long
# delete_wal_files_period_in_ms=20000

# The minimum size of wal files when throttle down in MultiLeader consensus
# If it's a value smaller than 0, use the default value 50 * 1024 * 1024 * 1024 bytes (50GB).
# Datatype: long
# multi_leader_throttle_threshold_in_byte=53687091200

# Maximum wait time of write cache in MultiLeader consensus
# If this value is less than or equal to 0, use the default value Long.MAX_VALUE.
# Datatype: long
# multi_leader_cache_window_time_in_ms=-1


####################
### Timestamp Precision
####################

# Use this value to set timestamp precision as "ms", "us" or "ns".
# Once the precision has been set, it can not be changed.
# Datatype: String
timestamp_precision=ms

# Default TTL for storage groups that are not set TTL by statements, If not set (default),
# the TTL will be unlimited.
# Notice: if this property is changed, previous created storage group which are not set TTL will
# also be affected. And negative values are accepted, which means you can only insert future
# data.
# Datatype: long
# Unit: ms
# default_ttl_in_ms=36000000

####################
### Tlog Size Configuration
####################
# max size for tag and attribute of one time series
# the unit is byte
# Datatype: int
# tag_attribute_total_size=700

####################
### Out of Order Data Configuration
####################

# Add a switch to drop ouf-of-order data
# Out-of-order data will impact the aggregation query a lot. Users may not care about discarding some out-of-order data.
# Datatype: boolean
# enable_discard_out_of_order_data=false

####################
### Client Configuration
####################

# The maximum session idle time. unit: ms
# Idle sessions are the ones that performs neither query or non-query operations for a period of time
# Set to 0 to disable session timeout
# Datatype: int
# session_timeout_threshold=0

####################
### Insert Control
####################

# When the waiting time (in ms) of an inserting exceeds this, throw an exception. 10000 by default.
# If the insertion has been rejected and the read load is low, it can be set larger
# Datatype: int
# max_waiting_time_when_insert_blocked=10000

####################
### Query Configurations
####################

# allowed max numbers of deduplicated path in one query
# it's just an advised value, the real limitation will be the smaller one between this and the one we calculated
# Datatype: int
# max_deduplicated_path_num=1000

# the default time period that used in fill query, -1 by default means infinite past time
# Datatype: int, Unit: ms
# default_fill_interval=-1

# the max execution time of a DriverTask
# Datatype: int, Unit: ms
# driver_task_execution_time_slice_in_ms=100

# the max capacity of a TsBlock
# Datatype: int, Unit: byte
# max_tsblock_size_in_bytes=1048576

# the max number of lines in a single TsBlock
# Datatype: int
# max_tsblock_line_numbers=1000

# time cost(ms) threshold for slow query
# Datatype: long
# slow_query_threshold=5000

####################
### External sort Configuration
####################
# Is external sort enable
# Datatype: boolean
# enable_external_sort=true

# The maximum number of simultaneous chunk reading for a single time series.
# If the num of simultaneous chunk reading is greater than external_sort_threshold, external sorting is used.
# When external_sort_threshold increases, the number of chunks sorted at the same time in memory may increase and this will occupy more memory.
# When external_sort_threshold decreases, triggering external sorting will increase the time-consuming.
# Datatype: int
# external_sort_threshold=1000

####################
### PIPE Configuration
####################

# White IP list of Sync client.
# Please use the form of network segment to present the range of IP, for example: 192.168.0.0/16
# If there are more than one IP segment, please separate them by commas
# The default is to allow all IP to sync
# Datatype: String
# ip_white_list=0.0.0.0/0


# The maximum number of retry when syncing a file to receiver fails.
# max_number_of_sync_file_retry=5

####################
### Configurations for watermark module
####################
# Datatype: boolean
# watermark_module_opened=false
# Datatype: String
# watermark_secret_key=IoTDB*2019@Beijing
# Datatype: String
# watermark_bit_string=100101110100
# Datatype: String
# watermark_method=GroupBasedLSBMethod(embed_row_cycle=2,embed_lsb_num=5)

####################
### Configurations for creating schema automatically
####################

# Whether creating schema automatically is enabled
# If true, then create storage group and timeseries automatically when not exists in insertion
# Or else, user need to create storage group and timeseries before insertion.
# Datatype: boolean
# enable_auto_create_schema=true

# Storage group level when creating schema automatically is enabled
# e.g. root.sg0.d1.s2
#      we will set root.sg0 as the storage group if storage group level is 1
# Datatype: int
# default_storage_group_level=1

# ALL data types: BOOLEAN, INT32, INT64, FLOAT, DOUBLE, TEXT

# register time series as which type when receiving boolean string "true" or "false"
# Datatype: TSDataType
# boolean_string_infer_type=BOOLEAN

# register time series as which type when receiving an integer string "67"
# Datatype: TSDataType
# integer_string_infer_type=FLOAT

# register time series as which type when receiving an integer string and using float may lose precision
# num > 2 ^ 24
# Datatype: TSDataType
# long_string_infer_type=DOUBLE

# register time series as which type when receiving a floating number string "6.7"
# Datatype: TSDataType
# floating_string_infer_type=FLOAT

# register time series as which type when receiving the Literal NaN. Values can be DOUBLE, FLOAT or TEXT
# Datatype: TSDataType
# nan_string_infer_type=DOUBLE

# BOOLEAN encoding when creating schema automatically is enabled
# Datatype: TSEncoding
# default_boolean_encoding=RLE

# INT32 encoding when creating schema automatically is enabled
# Datatype: TSEncoding
# default_int32_encoding=RLE

# INT64 encoding when creating schema automatically is enabled
# Datatype: TSEncoding
# default_int64_encoding=RLE

# FLOAT encoding when creating schema automatically is enabled
# Datatype: TSEncoding
# default_float_encoding=GORILLA

# DOUBLE encoding when creating schema automatically is enabled
# Datatype: TSEncoding
# default_double_encoding=GORILLA

# TEXT encoding when creating schema automatically is enabled
# Datatype: TSEncoding
# default_text_encoding=PLAIN

####################
### MQTT Broker Configuration
####################

# whether to enable the mqtt service.
# Datatype: boolean
# enable_mqtt_service=false

# the mqtt service binding host.
# Datatype: String
# mqtt_host=0.0.0.0

# the mqtt service binding port.
# Datatype: int
# mqtt_port=1883

# the handler pool size for handing the mqtt messages.
# Datatype: int
# mqtt_handler_pool_size=1

# the mqtt message payload formatter.
# Datatype: String
# mqtt_payload_formatter=json

# max length of mqtt message in byte
# Datatype: int
# mqtt_max_message_size=1048576

####################
### Authorization Configuration
####################

# which class to serve for authorization. By default, it is LocalFileAuthorizer.
# Another choice is org.apache.iotdb.db.auth.authorizer.OpenIdAuthorizer
# authorizer_provider_class=org.apache.iotdb.commons.auth.authorizer.LocalFileAuthorizer

# If OpenIdAuthorizer is enabled, then openID_url must be set.
# openID_url=

# admin username, default is root
# Datatype: string
# admin_name=root

# encryption provider class
# iotdb_server_encrypt_decrypt_provider=org.apache.iotdb.commons.security.encrypt.MessageDigestEncrypt

# encryption provided class parameter
# iotdb_server_encrypt_decrypt_provider_parameter=

# admin password, default is root
# Datatype: string
# admin_password=root

# Cache size of user and role
# Datatype: int
# author_cache_size=1000

# Cache expire time of user and role
# Datatype: int
# author_cache_expire_time=30


####################
### UDF Configuration
####################

# Used to estimate the memory usage of text fields in a UDF query.
# It is recommended to set this value to be slightly larger than the average length of all text
# records.
# Datatype: int
# udf_initial_byte_array_length_for_memory_control=48

# How much memory may be used in ONE UDF query (in MB).
# The upper limit is 20% of allocated memory for read.
# Datatype: float
# udf_memory_budget_in_mb=30.0

# UDF memory allocation ratio.
# The parameter form is a:b:c, where a, b, and c are integers.
# udf_reader_transformer_collector_memory_proportion=1:1:1

# UDF lib dir
# If this property is unset, system will save the data in the default relative path directory under
# the UDF folder(i.e., %CONFIGNODE_HOME%/ext/udf).
#
# If it is absolute, system will save the data in exact location it points to.
# If it is relative, system will save the data in the relative path directory it indicates under the
# UDF folder.
# Note: If data_dir is assigned an empty string(i.e.,zero-size), it will be handled as a relative
# path.
#
# For Window platform
# If its prefix is a drive specifier followed by "\\", or if its prefix is "\\\\", then the path is
# absolute. Otherwise, it is relative.
# udf_lib_dir=ext\\udf
#
# For Linux platform
# If its prefix is "/", then the path is absolute. Otherwise, it is relative.
# udf_lib_dir=ext/udf

# temporary lib dir
# If this property is unset, system will save the data in the default relative path directory under
# the UDF folder(i.e., %CONFIGNODE_HOME%/ext/temporary).
#
# If it is absolute, system will save the data in exact location it points to.
# If it is relative, system will save the data in the relative path directory it indicates under the
# UDF folder.
# Note: If data_dir is assigned an empty string(i.e.,zero-size), it will be handled as a relative
# path.
#
# For Window platform
# If its prefix is a drive specifier followed by "\\", or if its prefix is "\\\\", then the path is
# absolute. Otherwise, it is relative.
# udf_temporary_lib_dir=ext\\udf_temporary
#
# For Linux platform
# If its prefix is "/", then the path is absolute. Otherwise, it is relative.
# udf_temporary_lib_dir=ext/udf_temporary



####################
### Trigger Configuration
####################

# The size of log buffer for every trigger management operation plan. If the size of a trigger
# management operation plan is larger than this parameter, the trigger management operation plan
# will be rejected by TriggerManager.
# Datatype: int
# tlog_buffer_size=1048576

# Uncomment the following field to configure the trigger root directory.
# For Window platform
# If its prefix is a drive specifier followed by "\\", or if its prefix is "\\\\", then the path is
# absolute. Otherwise, it is relative.
# trigger_root_dir=ext\\trigger
# For Linux platform
# If its prefix is "/", then the path is absolute. Otherwise, it is relative.
# trigger_root_dir=ext/trigger

# temporary lib dir
# If this property is unset, system will save the data in the default relative path directory under
# the Trigger folder(i.e., ext/temporary).
#
# If it is absolute, system will save the data in exact location it points to.
# If it is relative, system will save the data in the relative path directory it indicates under the
# Trigger folder.
# Note: If data_dir is assigned an empty string(i.e.,zero-size), it will be handled as a relative
# path.
#
# For Window platform
# If its prefix is a drive specifier followed by "\\", or if its prefix is "\\\\", then the path is
# absolute. Otherwise, it is relative.
# trigger_temporary_lib_dir=ext\\trigger_temporary
#
# For Linux platform
# If its prefix is "/", then the path is absolute. Otherwise, it is relative.
# trigger_temporary_lib_dir=ext/trigger_temporary

# How many threads can be used for evaluating sliding windows. When <= 0, use CPU core number.
# Datatype: int
# concurrent_window_evaluation_thread=0

# Max number of window evaluation tasks that can be pending for execution. When <= 0, the value is
# 64 by default.
# Datatype: int
# max_pending_window_evaluation_tasks=64

# How many times will we retry to found an instance of stateful trigger on DataNodes
# 3 by default.
# Datatype: int
# stateful_trigger_retry_num_when_not_found=3


####################
### Time Partition Configuration
####################

# whether enable data partition. If disabled, all data belongs to partition 0
# Datatype: boolean
# enable_partition=true

# time range for partitioning data inside each data region, the unit is millisecond, default is equal to one week
# Datatype: long
# time_partition_interval_for_storage=604800000

####################
### Influx DB RPC Service Configuration
####################
# Datatype: boolean
# enable_influxdb_rpc_service=false

# Datatype: int
# influxdb_rpc_port=8086

####################
### Group By Fill Configuration
####################
# Datatype: float
# group_by_fill_cache_size_in_mb=1.0

####################
### Trigger Forward
####################
# Number of queues per forwarding trigger
trigger_forward_max_queue_number=8
# The length of one of the queues per forwarding trigger
trigger_forward_max_size_per_queue=2000
# Trigger forwarding data size per batch
trigger_forward_batch_size=50
# Trigger HTTP forward pool size
trigger_forward_http_pool_size=200
# Trigger HTTP forward pool max connection for per route
trigger_forward_http_pool_max_per_route=20
# Trigger MQTT forward pool size
trigger_forward_mqtt_pool_size=4

####################
### Cluster configuration
####################

####################
### Region configuration
####################

# ConfigNode consensus protocol type.
# This parameter is unmodifiable after ConfigNode starts for the first time.
# These consensus protocols are currently supported:
# 1. org.apache.iotdb.consensus.ratis.RatisConsensus(Raft protocol)
# Datatype: String
# cn_consensus_protocol_class=org.apache.iotdb.consensus.ratis.RatisConsensus

# SchemaRegion consensus protocol type.
# This parameter is unmodifiable after ConfigNode starts for the first time.
# These consensus protocols are currently supported:
# 1. org.apache.iotdb.consensus.standalone.StandAloneConsensus(Consensus patterns optimized specifically for single replica)
# 2. org.apache.iotdb.consensus.ratis.RatisConsensus(Raft protocol)
# Datatype: String
# schema_region_consensus_protocol_class=org.apache.iotdb.consensus.standalone.StandAloneConsensus

# The maximum number of SchemaRegion expected to be managed by each DataNode.
# Notice: Since each StorageGroup requires at least one SchemaRegion to manage its schema,
# this parameter doesn't limit the number of SchemaRegions when there are too many StorageGroups.
# Datatype: Double
# schema_region_per_data_node=1.0

# DataRegion consensus protocol type.
# This parameter is unmodifiable after ConfigNode starts for the first time.
# These consensus protocols are currently supported:
# 1. org.apache.iotdb.consensus.standalone.StandAloneConsensus(Consensus patterns optimized specifically for single replica)
# 2. org.apache.iotdb.consensus.multileader.MultiLeaderConsensus(weak consistency, high performance)
# 3. org.apache.iotdb.consensus.ratis.RatisConsensus(Raft protocol)
# Datatype: String
# data_region_consensus_protocol_class=org.apache.iotdb.consensus.standalone.StandAloneConsensus

# The maximum number of DataRegion expected to be managed by each processor.
# Notice: Since each StorageGroup requires at least two DataRegions to manage its data,
# this parameter doesn't limit the number of DataRegions when there are too many StorageGroups.
# Datatype: Double
# data_region_per_processor=0.5

# Region allocate strategy
# These allocate strategies are currently supported:
# 1. GREEDY(Default, when region is allocated, always choose the dataNode that has bean allocated the least regions)
# 2. COPY_SET(Random replication according to wight calculated from number of regions on all online dataNodes, suitable for large clusters)
# Datatype: String
# region_allocate_strategy=GREEDY

# All parameters in PartitionSlot configuration is unmodifiable after ConfigNode starts for the first time.
# And these parameters should be consistent within the ConfigNodeGroup.
# Number of SeriesPartitionSlots per StorageGroup
# Datatype: int
# series_partition_slot_num=10000


# SeriesPartitionSlot executor class
# These hashing algorithms are currently supported:
# 1. BKDRHashExecutor(Default)
# 2. APHashExecutor
# 3. JSHashExecutor
# 4. SDBMHashExecutor
# Also, if you want to implement your own SeriesPartition executor, you can inherit the SeriesPartitionExecutor class and
# modify this parameter to correspond to your Java class
# Datatype: String
# series_partition_executor_class=org.apache.iotdb.commons.partition.executor.hash.BKDRHashExecutor

# The routing policy of read/write requests
# These routing policy are currently supported:
# 1. leader(Default, routing to leader replica)
# 2. greedy(Routing to replica with the lowest load, might cause read un-consistent)
# Datatype: string
# routing_policy=leader

####################
### StorageGroup initial configuration
####################

# All parameters in StorageGroup configuration is unmodifiable after ConfigNode starts for the first time.
# And these parameters should be consistent within the ConfigNodeGroup.


# Default TTL for storage groups that are not set TTL by statements, in ms. If not set (default),
# the TTL will be unlimited.
# Notice: if this property is changed, previous created storage group which are not set TTL will
# also be affected. And negative values are accepted, which means you can only insert future data.
# Datatype: long
# default_ttl=36000000


# Time partition interval in milliseconds, default is equal to one week
# Datatype: long
# time_partition_interval_for_routing=604800000


# Default number of SchemaRegion replicas
# Datatype: int
# schema_replication_factor=1


# Default number of DataRegion replicas
# Datatype: int
# data_replication_factor=1

####################
### Read configuration
####################


# The read consistency level
# These consistency levels are currently supported:
# 1. strong(Default, read from the leader replica)
# 2. weak(Read from a random replica)
# Datatype: string
# read_consistency_level=strong

####################
### Heartbeat configuration
####################


# The heartbeat interval in milliseconds, default is 1000ms
# Datatype: long
# heartbeat_interval_in_ms=1000




####################
### RatisConsensus Configuration
####################

# max payload size for a single log-sync-RPC from leader to follower
# partition_region_ratis_log_appender_buffer_size_max = 4194304
# schema_region_ratis_log_appender_buffer_size_max = 4194304
# data_region_ratis_log_appender_buffer_size_max = 4194304

# trigger a snapshot when standalone_snapshot_trigger_threshold logs are written
# partition_region_standalone_snapshot_trigger_threshold=400000

# trigger a snapshot when ratis_snapshot_trigger_threshold logs are written
# partition_region_ratis_snapshot_trigger_threshold = 400000
# schema_region_ratis_snapshot_trigger_threshold = 400000
# data_region_ratis_snapshot_trigger_threshold = 400000

# allow flushing Raft Log asynchronously
# partition_region_ratis_log_unsafe_flush_enable = false
# schema_region_ratis_log_unsafe_flush_enable = false
# data_region_ratis_log_unsafe_flush_enable = false

# max capacity of a single Raft Log segment (by default 24MB)
# partition_region_ratis_log_segment_size_max = 25165824
# schema_region_ratis_log_segment_size_max = 25165824
# data_region_ratis_log_segment_size_max = 25165824

# flow control window for ratis grpc log appender
# partition_region_ratis_grpc_flow_control_window = 4194304
# schema_region_ratis_grpc_flow_control_window = 4194304
# data_region_ratis_grpc_flow_control_window = 4194304

# min election timeout for leader election
# partition_region_ratis_rpc_leader_election_timeout_min_ms = 2000
# schema_region_ratis_rpc_leader_election_timeout_min_ms = 2000
# data_region_ratis_rpc_leader_election_timeout_min_ms = 2000

# max election timeout for leader election
# partition_region_ratis_rpc_leader_election_timeout_max_ms = 4000
# schema_region_ratis_rpc_leader_election_timeout_max_ms = 4000
# data_region_ratis_rpc_leader_election_timeout_max_ms = 4000

# ratis client retry threshold
# partition_region_ratis_request_timeout_ms = 10000
# schema_region_ratis_request_timeout_ms = 10000
# data_region_ratis_request_timeout_ms = 10000

# currently we use exponential back-off retry policy for ratis
# partition_region_ratis_max_retry_attempts = 10
# partition_region_ratis_initial_sleep_time_ms = 100
# partition_region_ratis_max_sleep_time_ms = 10000
# schema_region_ratis_max_retry_attempts = 10
# schema_region_ratis_initial_sleep_time_ms = 100
# schema_region_ratis_max_sleep_time_ms = 10000
# data_region_ratis_max_retry_attempts = 10
# data_region_ratis_initial_sleep_time_ms = 100
# data_region_ratis_max_sleep_time_ms = 10000

# preserve certain logs when take snapshot and purge
# partition_region_ratis_preserve_logs_num_when_purge = 1000
# schema_region_ratis_preserve_logs_num_when_purge = 1000
# data_region_ratis_preserve_logs_num_when_purge = 1000

# first election timeout
# ratis_first_election_timeout_min_ms = 50
# ratis_first_election_timeout_max_ms = 150

####################
### Disk Monitor
####################


# Disk remaining threshold at which DataNode is set to ReadOnly status
# Datatype: double(percentage)
# disk_space_warning_threshold=5.0

####################
### Configurations for tsfile-format
####################

# Datatype: int
# group_size_in_byte=134217728

# The memory size for each series writer to pack page, default value is 64KB
# Datatype: int
# page_size_in_byte=65536

# The maximum number of data points in a page, default 1024*1024
# Datatype: int
# max_number_of_points_in_page=1048576

# The threshold for pattern matching in regex
# Datatype: int
# pattern_matching_threshold=1000000

# Max size limitation of input string
# Datatype: int
# max_string_length=128

# Floating-point precision
# Datatype: int
# float_precision=2

# Encoder configuration
# Encoder of time series, supports TS_2DIFF, PLAIN and RLE(run-length encoding), REGULAR and default value is TS_2DIFF
# time_encoder=TS_2DIFF

# Encoder of value series. default value is PLAIN.
# For int, long data type, also supports TS_2DIFF and RLE(run-length encoding), GORILLA and ZIGZAG.
# value_encoder=PLAIN

# Compression configuration
# Data compression method, supports UNCOMPRESSED, SNAPPY or LZ4. Default value is SNAPPY
# compressor=SNAPPY

# Maximum degree of a metadataIndex node, default value is 256
# Datatype: int
# max_degree_of_index_node=256

# time interval in minute for calculating query frequency
# Datatype: int
# frequency_interval_in_minute=1

# Signal-noise-ratio (SNR) of FREQ encoding
# Datatype: double
# freq_snr=40.0

# Block size of FREQ encoding
# Datatype: integer
# freq_block_size=1024


